{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joony0512/Statistics-and-NLP/blob/main/%5B7_1%5D_Lesk_Algorithm%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EB%8B%A8%EC%96%B4%EC%A4%91%EC%9D%98%EC%84%B1_%ED%95%B4%EC%86%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V5YBS-bs3gW"
      },
      "source": [
        "***nltk 패키지 다운로드***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzwbJnE-siDh",
        "outputId": "9bdf3300-671d-4354-89f4-30e78a796330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5) (1.15.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449922 sha256=dcb296e627fa8ac0e22c025ec9d6630c16f3b14ae996b6c58b5935544586360c\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.3\n",
            "    Uninstalling nltk-3.3:\n",
            "      Successfully uninstalled nltk-3.3\n",
            "Successfully installed nltk-3.4.5\n"
          ]
        }
      ],
      "source": [
        "!pip3 install nltk==3.4.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po12R4oGtz6S"
      },
      "source": [
        "***wordnet 관련 패키지 nltk import***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SknqGJv6tCW-",
        "outputId": "8a1eb0b5-6e73-48c6-8c1e-0986b713c019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4') # 코드 추가\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet \n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCfx2tE3uOVe"
      },
      "source": [
        "***단어와  문장에 나타난 단어에 대해  Best Sense 추출***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8I3ysskcBpYI"
      },
      "outputs": [],
      "source": [
        "def disambiguate(word, sentence, stopwords):\n",
        "        # Best sense 를 얻기위한 Lesk 알고리즘을 작성해보세요.\n",
        "        \n",
        "        word_senses = wordnet.synsets(word)\n",
        "        best_sense = word_senses[0]  # Assume that first sense is most freq.\n",
        "        max_overlap = 0\n",
        "        context = set(word_tokenize(sentence))\n",
        "        for sense in word_senses:\n",
        "            signature = tokenized_gloss(sense)\n",
        "            overlap = compute_overlap(signature, context, stopwords)\n",
        "            if overlap > max_overlap:\n",
        "                max_overlap = overlap\n",
        "                best_sense = sense\n",
        "                \n",
        "        return best_sense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olCLCgPeBv76"
      },
      "source": [
        "***sense의 definition에 대한 모든 token 추출***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GrMe88tC1SM"
      },
      "outputs": [],
      "source": [
        "def tokenized_gloss(sense):\n",
        "        tokens = set(word_tokenize(sense.definition()))\n",
        "        for example in sense.examples():\n",
        "            tokens.union(set(word_tokenize(example)))\n",
        "        return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk0kzsW6BwvS"
      },
      "source": [
        "***겹치는 단어 비교***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcduxEp5DH-T"
      },
      "outputs": [],
      "source": [
        "def compute_overlap(signature, context, stopwords):\n",
        "        gloss = signature.difference(stopwords)\n",
        "        return len(gloss.intersection(context))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WbpC6W6uXDz"
      },
      "source": [
        "***Main***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdqUjnqLuZJh",
        "outputId": "36c4843f-413b-42e4-d5db-c06796494380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word : eat\n",
            "Sense : eat.v.02\n",
            "Definition : eat a meal; take a meal\n",
            "Sentence : They eat a meal\n",
            "{'a', ';', 'eat', 'meal', 'take'}\n",
            "2\n",
            "Best sense:  Synset('eat.v.02')\n"
          ]
        }
      ],
      "source": [
        "stopwords = set(stopwords.words('english'))# NLTK에서 지정한 영어 불용어 처리 ex) i, my, they...\n",
        "sentence = (\"They eat a meal\")\n",
        "context = set(word_tokenize(sentence))\n",
        "word = 'eat'\n",
        "\n",
        "print(\"Word :\", word)\n",
        "syn = wordnet.synsets('eat')[1]\n",
        "print(\"Sense :\", syn.name())\n",
        "print(\"Definition :\", syn.definition())\n",
        "print(\"Sentence :\", sentence)\n",
        "\n",
        "signature = tokenized_gloss(syn)\n",
        "print(signature)\n",
        "print(compute_overlap(signature, context, stopwords))\n",
        "print(\"Best sense: \", disambiguate(word, sentence, stopwords))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsAPTnu7q432"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}